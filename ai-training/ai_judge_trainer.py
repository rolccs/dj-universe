# Sistema de entrenamiento de IA para evaluaci√≥n de batallas de DJ
# Utiliza TensorFlow/PyTorch para entrenar modelos de evaluaci√≥n autom√°tica

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
import librosa
import json
import os
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import threading
import queue

class DJBattleAITrainer:
    def __init__(self, config=None):
        self.config = config or {
            'sample_rate': 44100,
            'n_mels': 128,
            'n_fft': 2048,
            'hop_length': 512,
            'max_duration': 30,  # segundos
            'model_save_path': './models',
            'data_path': './training_data',
            'batch_size': 32,\n            'epochs': 100,\n            'learning_rate': 0.001,\n            'validation_split': 0.2\n        }\n        \n        self.feature_extractors = {\n            'technical': TechnicalFeatureExtractor(),\n            'musical': MusicalFeatureExtractor(),\n            'transition': TransitionFeatureExtractor(),\n            'crowd': CrowdResponseExtractor()\n        }\n        \n        self.models = {}\n        self.scalers = {}\n        self.training_history = {}\n        \n        self.setup_models()\n    \n    def setup_models(self):\n        \"\"\"Configurar diferentes modelos de evaluaci√≥n\"\"\"\n        \n        # Modelo para evaluaci√≥n t√©cnica (BPM matching, pitch accuracy)\n        self.models['technical'] = self.create_technical_model()\n        \n        # Modelo para evaluaci√≥n musical (harmonic mixing, key compatibility)\n        self.models['musical'] = self.create_musical_model()\n        \n        # Modelo para evaluaci√≥n de transiciones\n        self.models['transition'] = self.create_transition_model()\n        \n        # Modelo para respuesta de multitud\n        self.models['crowd'] = self.create_crowd_model()\n        \n        # Modelo ensemble para puntuaci√≥n final\n        self.models['ensemble'] = self.create_ensemble_model()\n    \n    def create_technical_model(self):\n        \"\"\"Modelo CNN-LSTM para an√°lisis t√©cnico\"\"\"\n        \n        model = models.Sequential([\n            # Capas convolucionales para an√°lisis espectral\n            layers.Conv2D(32, (3, 3), activation='relu', \n                         input_shape=(self.config['n_mels'], 130, 1)),\n            layers.BatchNormalization(),\n            layers.Conv2D(64, (3, 3), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D((2, 2)),\n            \n            layers.Conv2D(128, (3, 3), activation='relu'),\n            layers.BatchNormalization(),\n            layers.Conv2D(256, (3, 3), activation='relu'),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D((2, 2)),\n            \n            # Reshape para LSTM\n            layers.Reshape((-1, 256)),\n            \n            # Capas LSTM para an√°lisis temporal\n            layers.LSTM(128, return_sequences=True),\n            layers.Dropout(0.3),\n            layers.LSTM(64),\n            layers.Dropout(0.3),\n            \n            # Capas densas para clasificaci√≥n\n            layers.Dense(128, activation='relu'),\n            layers.Dropout(0.4),\n            layers.Dense(64, activation='relu'),\n            layers.Dense(32, activation='relu'),\n            \n            # Salidas m√∫ltiples para diferentes m√©tricas t√©cnicas\n            layers.Dense(8, activation='sigmoid', name='technical_scores')\n        ])\n        \n        model.compile(\n            optimizer=optimizers.Adam(learning_rate=self.config['learning_rate']),\n            loss='mse',\n            metrics=['mae', 'accuracy']\n        )\n        \n        return model\n    \n    def create_musical_model(self):\n        \"\"\"Modelo para an√°lisis musical y arm√≥nico\"\"\"\n        \n        # Input para caracter√≠sticas crom√°ticas\n        chroma_input = layers.Input(shape=(12,), name='chroma_input')\n        \n        # Input para caracter√≠sticas tonales\n        tonal_input = layers.Input(shape=(6,), name='tonal_input')\n        \n        # Input para caracter√≠sticas r√≠tmicas\n        rhythm_input = layers.Input(shape=(8,), name='rhythm_input')\n        \n        # Procesamiento de caracter√≠sticas crom√°ticas\n        chroma_dense = layers.Dense(24, activation='relu')(chroma_input)\n        chroma_dense = layers.Dropout(0.2)(chroma_dense)\n        chroma_dense = layers.Dense(12, activation='relu')(chroma_dense)\n        \n        # Procesamiento de caracter√≠sticas tonales\n        tonal_dense = layers.Dense(12, activation='relu')(tonal_input)\n        tonal_dense = layers.Dropout(0.2)(tonal_dense)\n        \n        # Procesamiento de caracter√≠sticas r√≠tmicas\n        rhythm_dense = layers.Dense(16, activation='relu')(rhythm_input)\n        rhythm_dense = layers.Dropout(0.2)(rhythm_dense)\n        \n        # Concatenar todas las caracter√≠sticas\n        combined = layers.Concatenate()([chroma_dense, tonal_dense, rhythm_dense])\n        \n        # Capas finales\n        combined = layers.Dense(64, activation='relu')(combined)\n        combined = layers.Dropout(0.3)(combined)\n        combined = layers.Dense(32, activation='relu')(combined)\n        \n        # Salida para compatibilidad musical\n        output = layers.Dense(5, activation='sigmoid', name='musical_scores')(combined)\n        \n        model = models.Model(\n            inputs=[chroma_input, tonal_input, rhythm_input],\n            outputs=output\n        )\n        \n        model.compile(\n            optimizer=optimizers.Adam(learning_rate=self.config['learning_rate']),\n            loss='mse',\n            metrics=['mae']\n        )\n        \n        return model\n    \n    def create_transition_model(self):\n        \"\"\"Modelo especializado en an√°lisis de transiciones\"\"\"\n        \n        # Arquitectura de red siamesa para comparar dos segmentos\n        input_shape = (self.config['n_mels'], 65, 1)  # Segmentos m√°s cortos\n        \n        def create_branch():\n            branch = models.Sequential([\n                layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n                layers.BatchNormalization(),\n                layers.Conv2D(64, (3, 3), activation='relu'),\n                layers.BatchNormalization(),\n                layers.MaxPooling2D((2, 2)),\n                \n                layers.Conv2D(128, (3, 3), activation='relu'),\n                layers.BatchNormalization(),\n                layers.GlobalAveragePooling2D(),\n                \n                layers.Dense(256, activation='relu'),\n                layers.Dropout(0.3),\n                layers.Dense(128, activation='relu')\n            ])\n            return branch\n        \n        # Dos ramas para los segmentos antes y despu√©s de la transici√≥n\n        branch = create_branch()\n        \n        input_a = layers.Input(shape=input_shape, name='segment_before')\n        input_b = layers.Input(shape=input_shape, name='segment_after')\n        \n        encoded_a = branch(input_a)\n        encoded_b = branch(input_b)\n        \n        # Calcular distancia y similitud\n        distance = layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([encoded_a, encoded_b])\n        similarity = layers.Lambda(lambda x: x[0] * x[1])([encoded_a, encoded_b])\n        \n        # Combinar caracter√≠sticas\n        combined = layers.Concatenate()([distance, similarity, encoded_a, encoded_b])\n        \n        # Capas finales para evaluaci√≥n de transici√≥n\n        combined = layers.Dense(256, activation='relu')(combined)\n        combined = layers.Dropout(0.4)(combined)\n        combined = layers.Dense(128, activation='relu')(combined)\n        combined = layers.Dense(64, activation='relu')(combined)\n        \n        # Salida: calidad de transici√≥n (0-1)\n        output = layers.Dense(1, activation='sigmoid', name='transition_quality')(combined)\n        \n        model = models.Model(inputs=[input_a, input_b], outputs=output)\n        \n        model.compile(\n            optimizer=optimizers.Adam(learning_rate=self.config['learning_rate']),\n            loss='binary_crossentropy',\n            metrics=['accuracy', 'precision', 'recall']\n        )\n        \n        return model\n    \n    def create_crowd_model(self):\n        \"\"\"Modelo para predecir respuesta de la audiencia\"\"\"\n        \n        model = models.Sequential([\n            # Entrada: caracter√≠sticas de audio + metadatos\n            layers.Input(shape=(50,)),  # Caracter√≠sticas combinadas\n            \n            layers.Dense(128, activation='relu'),\n            layers.BatchNormalization(),\n            layers.Dropout(0.3),\n            \n            layers.Dense(64, activation='relu'),\n            layers.BatchNormalization(),\n            layers.Dropout(0.3),\n            \n            layers.Dense(32, activation='relu'),\n            layers.Dropout(0.2),\n            \n            # Salida: nivel de energ√≠a/respuesta de la multitud\n            layers.Dense(1, activation='sigmoid', name='crowd_response')\n        ])\n        \n        model.compile(\n            optimizer=optimizers.Adam(learning_rate=self.config['learning_rate']),\n            loss='mse',\n            metrics=['mae']\n        )\n        \n        return model\n    \n    def create_ensemble_model(self):\n        \"\"\"Modelo ensemble que combina todas las evaluaciones\"\"\"\n        \n        # Inputs de otros modelos\n        technical_input = layers.Input(shape=(8,), name='technical_features')\n        musical_input = layers.Input(shape=(5,), name='musical_features')\n        transition_input = layers.Input(shape=(1,), name='transition_features')\n        crowd_input = layers.Input(shape=(1,), name='crowd_features')\n        \n        # Pesos aprendibles para cada componente\n        technical_weighted = layers.Dense(8, activation='relu')(technical_input)\n        musical_weighted = layers.Dense(5, activation='relu')(musical_input)\n        transition_weighted = layers.Dense(4, activation='relu')(transition_input)\n        crowd_weighted = layers.Dense(2, activation='relu')(crowd_input)\n        \n        # Combinar todos los componentes\n        combined = layers.Concatenate()([\n            technical_weighted, musical_weighted, \n            transition_weighted, crowd_weighted\n        ])\n        \n        # Capas de decisi√≥n final\n        combined = layers.Dense(32, activation='relu')(combined)\n        combined = layers.Dropout(0.3)(combined)\n        combined = layers.Dense(16, activation='relu')(combined)\n        \n        # Puntuaci√≥n final (0-100)\n        final_score = layers.Dense(1, activation='linear', name='final_score')(combined)\n        \n        # Ranking categ√≥rico (Amateur, Intermediate, Professional, Expert)\n        ranking = layers.Dense(4, activation='softmax', name='skill_ranking')(combined)\n        \n        model = models.Model(\n            inputs=[technical_input, musical_input, transition_input, crowd_input],\n            outputs=[final_score, ranking]\n        )\n        \n        model.compile(\n            optimizer=optimizers.Adam(learning_rate=self.config['learning_rate']),\n            loss={\n                'final_score': 'mse',\n                'skill_ranking': 'categorical_crossentropy'\n            },\n            metrics={\n                'final_score': ['mae'],\n                'skill_ranking': ['accuracy']\n            },\n            loss_weights={'final_score': 0.7, 'skill_ranking': 0.3}\n        )\n        \n        return model\n    \n    def prepare_training_data(self, data_directory):\n        \"\"\"Preparar datos de entrenamiento desde archivos de audio y metadatos\"\"\"\n        \n        print(\"üìä Preparando datos de entrenamiento...\")\n        \n        # Cargar datos existentes o crear nuevos\n        training_data = {\n            'technical': {'X': [], 'y': []},\n            'musical': {'X': [], 'y': []},\n            'transition': {'X': [], 'y': []},\n            'crowd': {'X': [], 'y': []}\n        }\n        \n        # Procesar archivos de audio\n        audio_files = [f for f in os.listdir(data_directory) if f.endswith(('.wav', '.mp3'))]\n        \n        for audio_file in audio_files:\n            try {\n                file_path = os.path.join(data_directory, audio_file)\n                metadata_file = file_path.replace('.wav', '.json').replace('.mp3', '.json')\n                \n                if not os.path.exists(metadata_file):\n                    continue\n                \n                # Cargar audio\n                audio, sr = librosa.load(file_path, sr=self.config['sample_rate'])\n                \n                # Cargar metadatos (evaluaciones humanas)\n                with open(metadata_file, 'r') as f:\n                    metadata = json.load(f)\n                \n                # Extraer caracter√≠sticas para cada modelo\n                features = self.extract_all_features(audio, sr, metadata)\n                \n                # Agregar a datasets de entrenamiento\n                for model_type, data in features.items():\n                    if data['X'] is not None and data['y'] is not None:\n                        training_data[model_type]['X'].append(data['X'])\n                        training_data[model_type]['y'].append(data['y'])\n                \n                print(f\"‚úÖ Procesado: {audio_file}\")\n                \n            } catch Exception as e:\n                print(f\"‚ùå Error procesando {audio_file}: {str(e)}\")\n                continue\n        \n        # Convertir a arrays numpy\n        for model_type in training_data:\n            if training_data[model_type]['X']:\n                training_data[model_type]['X'] = np.array(training_data[model_type]['X'])\n                training_data[model_type]['y'] = np.array(training_data[model_type]['y'])\n            else:\n                print(f\"‚ö†Ô∏è No hay datos para el modelo {model_type}\")\n        \n        return training_data\n    \n    def extract_all_features(self, audio, sr, metadata):\n        \"\"\"Extraer todas las caracter√≠sticas necesarias para el entrenamiento\"\"\"\n        \n        features = {}\n        \n        try {\n            # Caracter√≠sticas t√©cnicas\n            technical_features = self.feature_extractors['technical'].extract(audio, sr)\n            technical_labels = metadata.get('technical_scores', np.zeros(8))\n            features['technical'] = {\n                'X': technical_features,\n                'y': technical_labels\n            }\n            \n            # Caracter√≠sticas musicales\n            musical_features = self.feature_extractors['musical'].extract(audio, sr)\n            musical_labels = metadata.get('musical_scores', np.zeros(5))\n            features['musical'] = {\n                'X': musical_features,\n                'y': musical_labels\n            }\n            \n            # Caracter√≠sticas de transici√≥n\n            transition_features = self.feature_extractors['transition'].extract(audio, sr)\n            transition_labels = metadata.get('transition_quality', 0.5)\n            features['transition'] = {\n                'X': transition_features,\n                'y': transition_labels\n            }\n            \n            # Caracter√≠sticas de respuesta de multitud\n            crowd_features = self.feature_extractors['crowd'].extract(audio, sr)\n            crowd_labels = metadata.get('crowd_response', 0.5)\n            features['crowd'] = {\n                'X': crowd_features,\n                'y': crowd_labels\n            }\n            \n        } except Exception as e:\n            print(f\"‚ùå Error extrayendo caracter√≠sticas: {str(e)}\")\n            for model_type in ['technical', 'musical', 'transition', 'crowd']:\n                features[model_type] = {'X': None, 'y': None}\n        \n        return features\n    \n    def train_all_models(self, training_data):\n        \"\"\"Entrenar todos los modelos\"\"\"\n        \n        print(\"üöÄ Iniciando entrenamiento de modelos...\")\n        \n        for model_name in ['technical', 'musical', 'transition', 'crowd']:\n            if model_name in training_data and len(training_data[model_name]['X']) > 0:\n                print(f\"\\nüî• Entrenando modelo {model_name}...\")\n                self.train_single_model(model_name, training_data[model_name])\n            else:\n                print(f\"‚ö†Ô∏è Saltando {model_name} - datos insuficientes\")\n        \n        # Entrenar modelo ensemble despu√©s de los individuales\n        self.train_ensemble_model(training_data)\n    \n    def train_single_model(self, model_name, data):\n        \"\"\"Entrenar un modelo individual\"\"\"\n        \n        X, y = data['X'], data['y']\n        \n        # Dividir datos\n        X_train, X_val, y_train, y_val = train_test_split(\n            X, y, test_size=self.config['validation_split'], random_state=42\n        )\n        \n        # Normalizar datos si es necesario\n        if model_name in ['musical', 'crowd']:\n            scaler = StandardScaler()\n            X_train = scaler.fit_transform(X_train)\n            X_val = scaler.transform(X_val)\n            self.scalers[model_name] = scaler\n        \n        # Callbacks\n        callbacks_list = [\n            callbacks.EarlyStopping(\n                monitor='val_loss',\n                patience=15,\n                restore_best_weights=True\n            ),\n            callbacks.ReduceLROnPlateau(\n                monitor='val_loss',\n                factor=0.5,\n                patience=8,\n                min_lr=1e-7\n            ),\n            callbacks.ModelCheckpoint(\n                filepath=f\"{self.config['model_save_path']}/{model_name}_best.h5\",\n                monitor='val_loss',\n                save_best_only=True\n            )\n        ]\n        \n        # Entrenar modelo\n        history = self.models[model_name].fit(\n            X_train, y_train,\n            batch_size=self.config['batch_size'],\n            epochs=self.config['epochs'],\n            validation_data=(X_val, y_val),\n            callbacks=callbacks_list,\n            verbose=1\n        )\n        \n        self.training_history[model_name] = history.history\n        \n        # Evaluar modelo\n        self.evaluate_model(model_name, X_val, y_val)\n    \n    def evaluate_model(self, model_name, X_val, y_val):\n        \"\"\"Evaluar rendimiento del modelo\"\"\"\n        \n        print(f\"\\nüìä Evaluando modelo {model_name}...\")\n        \n        # Predicciones\n        predictions = self.models[model_name].predict(X_val)\n        \n        # M√©tricas\n        if model_name == 'transition':\n            # Clasificaci√≥n binaria\n            pred_binary = (predictions > 0.5).astype(int)\n            y_binary = (y_val > 0.5).astype(int)\n            \n            print(classification_report(y_binary, pred_binary))\n        else:\n            # Regresi√≥n\n            mse = np.mean((predictions - y_val) ** 2)\n            mae = np.mean(np.abs(predictions - y_val))\n            \n            print(f\"MSE: {mse:.4f}\")\n            print(f\"MAE: {mae:.4f}\")\n        \n        # Guardar m√©tricas\n        metrics_file = f\"{self.config['model_save_path']}/{model_name}_metrics.json\"\n        with open(metrics_file, 'w') as f:\n            json.dump({\n                'mse': float(mse) if 'mse' in locals() else None,\n                'mae': float(mae) if 'mae' in locals() else None,\n                'training_history': self.training_history.get(model_name, {})\n            }, f, indent=2)\n    \n    def train_ensemble_model(self, training_data):\n        \"\"\"Entrenar el modelo ensemble\"\"\"\n        \n        print(\"\\nüéØ Entrenando modelo ensemble...\")\n        \n        # Generar predicciones de modelos base para entrenamiento del ensemble\n        ensemble_X, ensemble_y = self.prepare_ensemble_data(training_data)\n        \n        if ensemble_X is None:\n            print(\"‚ö†Ô∏è No se puede entrenar ensemble - datos insuficientes\")\n            return\n        \n        # Entrenar ensemble\n        X_train, X_val, y_train, y_val = train_test_split(\n            ensemble_X, ensemble_y, test_size=0.2, random_state=42\n        )\n        \n        history = self.models['ensemble'].fit(\n            X_train, y_train,\n            batch_size=self.config['batch_size'],\n            epochs=50,  # Menos √©pocas para ensemble\n            validation_data=(X_val, y_val),\n            verbose=1\n        )\n        \n        self.training_history['ensemble'] = history.history\n    \n    def save_models(self):\n        \"\"\"Guardar todos los modelos entrenados\"\"\"\n        \n        print(\"üíæ Guardando modelos...\")\n        \n        # Crear directorio si no existe\n        os.makedirs(self.config['model_save_path'], exist_ok=True)\n        \n        # Guardar modelos\n        for model_name, model in self.models.items():\n            model_path = f\"{self.config['model_save_path']}/{model_name}_model.h5\"\n            model.save(model_path)\n            print(f\"‚úÖ Guardado: {model_path}\")\n        \n        # Guardar scalers\n        for scaler_name, scaler in self.scalers.items():\n            scaler_path = f\"{self.config['model_save_path']}/{scaler_name}_scaler.pkl\"\n            with open(scaler_path, 'wb') as f:\n                pickle.dump(scaler, f)\n        \n        # Guardar configuraci√≥n\n        config_path = f\"{self.config['model_save_path']}/training_config.json\"\n        with open(config_path, 'w') as f:\n            json.dump(self.config, f, indent=2)\n        \n        print(\"‚úÖ Todos los modelos guardados exitosamente\")\n    \n    def load_models(self, model_path=None):\n        \"\"\"Cargar modelos preentrenados\"\"\"\n        \n        model_path = model_path or self.config['model_save_path']\n        \n        print(f\"üìÅ Cargando modelos desde {model_path}...\")\n        \n        try:\n            for model_name in self.models.keys():\n                model_file = f\"{model_path}/{model_name}_model.h5\"\n                if os.path.exists(model_file):\n                    self.models[model_name] = tf.keras.models.load_model(model_file)\n                    print(f\"‚úÖ Cargado: {model_name}\")\n                \n                # Cargar scaler si existe\n                scaler_file = f\"{model_path}/{model_name}_scaler.pkl\"\n                if os.path.exists(scaler_file):\n                    with open(scaler_file, 'rb') as f:\n                        self.scalers[model_name] = pickle.load(f)\n            \n            print(\"‚úÖ Modelos cargados exitosamente\")\n            \n        } except Exception as e:\n            print(f\"‚ùå Error cargando modelos: {str(e)}\")\n    \n    # M√©todo principal de entrenamiento\n    def train(self, data_directory):\n        \"\"\"Proceso completo de entrenamiento\"\"\"\n        \n        print(\"üéØ Iniciando entrenamiento completo del sistema IA...\")\n        \n        # Preparar datos\n        training_data = self.prepare_training_data(data_directory)\n        \n        # Entrenar modelos\n        self.train_all_models(training_data)\n        \n        # Guardar modelos\n        self.save_models()\n        \n        print(\"üéâ Entrenamiento completo finalizado!\")\n\n\n# Clases auxiliares para extracci√≥n de caracter√≠sticas\n\nclass TechnicalFeatureExtractor:\n    def extract(self, audio, sr):\n        \"\"\"Extraer caracter√≠sticas t√©cnicas\"\"\"\n        \n        # Melspectrogram para an√°lisis espectral\n        mel_spec = librosa.feature.melspectrogram(\n            y=audio, sr=sr, n_mels=128, fmax=8000\n        )\n        mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n        \n        # Normalizar y redimensionar\n        mel_db = (mel_db - mel_db.mean()) / mel_db.std()\n        \n        # Asegurar tama√±o fijo\n        target_frames = 130\n        if mel_db.shape[1] < target_frames:\n            # Pad con ceros\n            pad_width = target_frames - mel_db.shape[1]\n            mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant')\n        else:\n            # Truncar\n            mel_db = mel_db[:, :target_frames]\n        \n        return mel_db.reshape(128, 130, 1)\n\nclass MusicalFeatureExtractor:\n    def extract(self, audio, sr):\n        \"\"\"Extraer caracter√≠sticas musicales\"\"\"\n        \n        # Chroma features\n        chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n        chroma_mean = np.mean(chroma, axis=1)\n        \n        # Tonal features\n        tonnetz = librosa.feature.tonnetz(y=audio, sr=sr)\n        tonnetz_mean = np.mean(tonnetz, axis=1)\n        \n        # Tempo y rhythm features\n        tempo, beats = librosa.beat.beat_track(y=audio, sr=sr)\n        tempo_features = [\n            tempo,\n            len(beats) / (len(audio) / sr),  # beats per second\n            np.std(np.diff(beats)) if len(beats) > 1 else 0,  # tempo variability\n        ]\n        \n        # Spectral features\n        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n        zcr = librosa.feature.zero_crossing_rate(audio)\n        \n        rhythm_features = [\n            np.mean(spectral_centroids),\n            np.std(spectral_centroids),\n            np.mean(spectral_rolloff),\n            np.std(spectral_rolloff),\n            np.mean(zcr)\n        ]\n        \n        return [chroma_mean, tonnetz_mean, tempo_features + rhythm_features]\n\nclass TransitionFeatureExtractor:\n    def extract(self, audio, sr):\n        \"\"\"Extraer caracter√≠sticas de transiciones\"\"\"\n        \n        # Dividir audio en segmentos para an√°lisis de transiciones\n        segment_length = sr * 15  # 15 segundos\n        \n        if len(audio) < segment_length * 2:\n            # Audio muy corto, usar padding\n            audio = np.pad(audio, (0, segment_length * 2 - len(audio)), mode='constant')\n        \n        # Tomar dos segmentos consecutivos\n        mid_point = len(audio) // 2\n        segment1 = audio[mid_point - segment_length//2:mid_point + segment_length//2]\n        segment2 = audio[mid_point:mid_point + segment_length]\n        \n        # Extraer mel spectrograms para ambos segmentos\n        mel1 = librosa.feature.melspectrogram(y=segment1, sr=sr, n_mels=128)\n        mel2 = librosa.feature.melspectrogram(y=segment2, sr=sr, n_mels=128)\n        \n        # Normalizar\n        mel1_db = librosa.power_to_db(mel1, ref=np.max)\n        mel2_db = librosa.power_to_db(mel2, ref=np.max)\n        \n        # Redimensionar a tama√±o fijo\n        target_frames = 65\n        for mel_db in [mel1_db, mel2_db]:\n            if mel_db.shape[1] < target_frames:\n                pad_width = target_frames - mel_db.shape[1]\n                mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant')\n            else:\n                mel_db = mel_db[:, :target_frames]\n        \n        return [mel1_db.reshape(128, 65, 1), mel2_db.reshape(128, 65, 1)]\n\nclass CrowdResponseExtractor:\n    def extract(self, audio, sr):\n        \"\"\"Extraer caracter√≠sticas relacionadas con respuesta de multitud\"\"\"\n        \n        # Caracter√≠sticas de energ√≠a\n        rms = librosa.feature.rms(y=audio)\n        energy_mean = np.mean(rms)\n        energy_std = np.std(rms)\n        energy_max = np.max(rms)\n        \n        # Caracter√≠sticas espectrales\n        spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)\n        \n        # Caracter√≠sticas de tempo\n        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n        \n        # MFCC para caracter√≠sticas t√≠mbricas\n        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n        mfcc_means = np.mean(mfccs, axis=1)\n        \n        # Caracter√≠sticas de contraste espectral\n        contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n        contrast_mean = np.mean(contrast, axis=1)\n        \n        # Combinar todas las caracter√≠sticas\n        features = np.concatenate([\n            [energy_mean, energy_std, energy_max],\n            [np.mean(spectral_centroids), np.std(spectral_centroids)],\n            [np.mean(spectral_rolloff), np.std(spectral_rolloff)],\n            [np.mean(spectral_bandwidth), np.std(spectral_bandwidth)],\n            [tempo],\n            mfcc_means,\n            contrast_mean\n        ])\n        \n        return features\n\nif __name__ == \"__main__\":\n    # Ejemplo de uso\n    trainer = DJBattleAITrainer()\n    \n    # Entrenar con datos de ejemplo\n    # trainer.train('./training_data')\n    \n    print(\"üéØ Sistema de entrenamiento IA listo para usar\")"