# Sistema de inferencia IA para evaluaci√≥n en tiempo real de batallas DJ
# Utiliza modelos preentrenados para evaluar performance en vivo

import numpy as np
import tensorflow as tf
import librosa
import json
import pickle
import threading
import queue
import time
from datetime import datetime
import websocket
import logging

class DJBattleAIJudge:
    def __init__(self, model_path='./models', config=None):
        self.model_path = model_path
        self.config = config or {
            'sample_rate': 44100,
            'chunk_duration': 15,  # segundos por an√°lisis
            'overlap': 5,  # segundos de overlap
            'confidence_threshold': 0.7,
            'real_time': True,
            'websocket_url': 'ws://localhost:3001/ai-judge'
        }
        
        self.models = {}
        self.scalers = {}
        self.is_running = False
        self.audio_queue = queue.Queue()
        self.results_queue = queue.Queue()
        
        # Buffers para an√°lisis en tiempo real
        self.audio_buffer = np.array([])
        self.analysis_results = []
        
        # WebSocket para comunicaci√≥n en tiempo real
        self.ws = None
        
        self.load_models()
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(levelname)s - %(message)s'\n        )\n        self.logger = logging.getLogger(__name__)\n    \n    def load_models(self):\n        \"\"\"Cargar modelos preentrenados\"\"\"\n        \n        self.logger.info(\"üîÑ Cargando modelos IA...\")\n        \n        model_files = {\n            'technical': f\"{self.model_path}/technical_model.h5\",\n            'musical': f\"{self.model_path}/musical_model.h5\",\n            'transition': f\"{self.model_path}/transition_model.h5\",\n            'crowd': f\"{self.model_path}/crowd_model.h5\",\n            'ensemble': f\"{self.model_path}/ensemble_model.h5\"\n        }\n        \n        try:\n            for model_name, model_file in model_files.items():\n                if os.path.exists(model_file):\n                    self.models[model_name] = tf.keras.models.load_model(model_file)\n                    self.logger.info(f\"‚úÖ Cargado modelo: {model_name}\")\n                    \n                    # Cargar scaler si existe\n                    scaler_file = f\"{self.model_path}/{model_name}_scaler.pkl\"\n                    if os.path.exists(scaler_file):\n                        with open(scaler_file, 'rb') as f:\n                            self.scalers[model_name] = pickle.load(f)\n                else:\n                    self.logger.warning(f\"‚ö†Ô∏è Modelo no encontrado: {model_file}\")\n            \n            self.logger.info(\"‚úÖ Modelos cargados exitosamente\")\n            \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error cargando modelos: {str(e)}\")\n            raise\n    \n    def connect_websocket(self):\n        \"\"\"Conectar a WebSocket para comunicaci√≥n en tiempo real\"\"\"\n        \n        try:\n            self.ws = websocket.WebSocketApp(\n                self.config['websocket_url'],\n                on_message=self.on_websocket_message,\n                on_error=self.on_websocket_error,\n                on_close=self.on_websocket_close,\n                on_open=self.on_websocket_open\n            )\n            \n            # Ejecutar en hilo separado\n            ws_thread = threading.Thread(target=self.ws.run_forever)\n            ws_thread.daemon = True\n            ws_thread.start()\n            \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error conectando WebSocket: {str(e)}\")\n    \n    def on_websocket_open(self, ws):\n        self.logger.info(\"üîó Conectado a WebSocket del servidor\")\n        \n        # Registrar como AI Judge\n        registration = {\n            'type': 'ai_judge_registration',\n            'models_loaded': list(self.models.keys()),\n            'timestamp': datetime.now().isoformat()\n        }\n        ws.send(json.dumps(registration))\n    \n    def on_websocket_message(self, ws, message):\n        try:\n            data = json.loads(message)\n            \n            if data['type'] == 'audio_chunk':\n                # Recibir chunk de audio para an√°lisis\n                audio_data = np.array(data['audio_data'])\n                self.process_audio_chunk(audio_data, data.get('metadata', {}))\n                \n            elif data['type'] == 'battle_start':\n                self.start_battle_analysis(data['battle_id'])\n                \n            elif data['type'] == 'battle_end':\n                self.end_battle_analysis(data['battle_id'])\n                \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error procesando mensaje WebSocket: {str(e)}\")\n    \n    def on_websocket_error(self, ws, error):\n        self.logger.error(f\"‚ùå Error WebSocket: {str(error)}\")\n    \n    def on_websocket_close(self, ws, close_status_code, close_msg):\n        self.logger.info(\"üîå Conexi√≥n WebSocket cerrada\")\n    \n    def start_battle_analysis(self, battle_id):\n        \"\"\"Iniciar an√°lisis en tiempo real de una batalla\"\"\"\n        \n        self.logger.info(f\"‚öîÔ∏è Iniciando an√°lisis IA para batalla: {battle_id}\")\n        \n        self.current_battle_id = battle_id\n        self.is_running = True\n        self.audio_buffer = np.array([])\n        self.analysis_results = []\n        \n        # Iniciar hilo de an√°lisis\n        analysis_thread = threading.Thread(target=self.analysis_loop)\n        analysis_thread.daemon = True\n        analysis_thread.start()\n        \n        # Notificar al servidor\n        if self.ws:\n            response = {\n                'type': 'ai_analysis_started',\n                'battle_id': battle_id,\n                'timestamp': datetime.now().isoformat()\n            }\n            self.ws.send(json.dumps(response))\n    \n    def process_audio_chunk(self, audio_data, metadata):\n        \"\"\"Procesar chunk de audio en tiempo real\"\"\"\n        \n        if not self.is_running:\n            return\n        \n        # Agregar al buffer\n        self.audio_buffer = np.concatenate([self.audio_buffer, audio_data])\n        \n        # Mantener buffer de tama√±o fijo\n        max_buffer_size = self.config['sample_rate'] * 60  # 1 minuto\n        if len(self.audio_buffer) > max_buffer_size:\n            self.audio_buffer = self.audio_buffer[-max_buffer_size:]\n        \n        # Agregar a cola para an√°lisis\n        self.audio_queue.put({\n            'audio': audio_data.copy(),\n            'metadata': metadata,\n            'timestamp': time.time()\n        })\n    \n    def analysis_loop(self):\n        \"\"\"Loop principal de an√°lisis en tiempo real\"\"\"\n        \n        self.logger.info(\"üî• Iniciando loop de an√°lisis en tiempo real\")\n        \n        while self.is_running:\n            try:\n                # Esperar por chunk de audio\n                audio_chunk = self.audio_queue.get(timeout=1.0)\n                \n                # Analizar chunk\n                results = self.analyze_audio_chunk(\n                    audio_chunk['audio'],\n                    audio_chunk['metadata']\n                )\n                \n                if results:\n                    results['timestamp'] = audio_chunk['timestamp']\n                    self.analysis_results.append(results)\n                    \n                    # Enviar resultados en tiempo real\n                    self.send_real_time_results(results)\n                    \n                    # Mantener solo resultados recientes\n                    if len(self.analysis_results) > 100:\n                        self.analysis_results = self.analysis_results[-50:]\n                \n            except queue.Empty:\n                continue\n            except Exception as e:\n                self.logger.error(f\"‚ùå Error en an√°lisis: {str(e)}\")\n    \n    def analyze_audio_chunk(self, audio, metadata):\n        \"\"\"Analizar un chunk de audio con todos los modelos\"\"\"\n        \n        try:\n            # Asegurar duraci√≥n m√≠nima\n            min_duration = self.config['sample_rate'] * 10  # 10 segundos\n            if len(audio) < min_duration:\n                return None\n            \n            # Extraer caracter√≠sticas\n            features = self.extract_features(audio, self.config['sample_rate'])\n            \n            # Evaluar con cada modelo\n            results = {\n                'technical': None,\n                'musical': None,\n                'transition': None,\n                'crowd': None,\n                'final_score': None,\n                'confidence': 0.0\n            }\n            \n            # Modelo t√©cnico\n            if 'technical' in self.models and features['technical'] is not None:\n                technical_pred = self.models['technical'].predict(\n                    np.expand_dims(features['technical'], axis=0),\n                    verbose=0\n                )[0]\n                results['technical'] = {\n                    'bpm_accuracy': float(technical_pred[0]),\n                    'pitch_accuracy': float(technical_pred[1]),\n                    'beat_matching': float(technical_pred[2]),\n                    'transition_smoothness': float(technical_pred[3]),\n                    'timing_precision': float(technical_pred[4]),\n                    'mix_quality': float(technical_pred[5]),\n                    'eq_balance': float(technical_pred[6]),\n                    'overall_technique': float(technical_pred[7])\n                }\n            \n            # Modelo musical\n            if 'musical' in self.models and features['musical'] is not None:\n                musical_input = features['musical']\n                if 'musical' in self.scalers:\n                    # Para el modelo musical necesitamos preparar las entradas correctamente\n                    chroma_features = musical_input[0]\n                    tonal_features = musical_input[1]\n                    rhythm_features = musical_input[2]\n                    \n                    musical_pred = self.models['musical'].predict([\n                        np.expand_dims(chroma_features, axis=0),\n                        np.expand_dims(tonal_features, axis=0),\n                        np.expand_dims(rhythm_features, axis=0)\n                    ], verbose=0)[0]\n                    \n                    results['musical'] = {\n                        'harmonic_mixing': float(musical_pred[0]),\n                        'key_compatibility': float(musical_pred[1]),\n                        'musical_flow': float(musical_pred[2]),\n                        'genre_consistency': float(musical_pred[3]),\n                        'creativity': float(musical_pred[4])\n                    }\n            \n            # Modelo de transici√≥n\n            if 'transition' in self.models and features['transition'] is not None:\n                transition_pred = self.models['transition'].predict(\n                    features['transition'],\n                    verbose=0\n                )[0]\n                results['transition'] = {\n                    'quality': float(transition_pred[0])\n                }\n            \n            # Modelo de respuesta de multitud\n            if 'crowd' in self.models and features['crowd'] is not None:\n                crowd_input = features['crowd']\n                if 'crowd' in self.scalers:\n                    crowd_input = self.scalers['crowd'].transform(\n                        crowd_input.reshape(1, -1)\n                    )[0]\n                \n                crowd_pred = self.models['crowd'].predict(\n                    np.expand_dims(crowd_input, axis=0),\n                    verbose=0\n                )[0]\n                \n                results['crowd'] = {\n                    'energy_level': float(crowd_pred[0])\n                }\n            \n            # Modelo ensemble para puntuaci√≥n final\n            if 'ensemble' in self.models and all(results[k] is not None for k in ['technical', 'musical', 'transition', 'crowd']):\n                ensemble_input = self.prepare_ensemble_input(results)\n                \n                ensemble_pred = self.models['ensemble'].predict(\n                    ensemble_input,\n                    verbose=0\n                )\n                \n                final_score = ensemble_pred[0][0]  # Score\n                skill_ranking = ensemble_pred[1][0]  # Ranking probabilities\n                \n                results['final_score'] = float(final_score[0]) if len(final_score) > 0 else 0.0\n                results['skill_ranking'] = {\n                    'amateur': float(skill_ranking[0]),\n                    'intermediate': float(skill_ranking[1]),\n                    'professional': float(skill_ranking[2]),\n                    'expert': float(skill_ranking[3])\n                }\n                \n                # Calcular confianza general\n                results['confidence'] = float(np.max(skill_ranking))\n            \n            return results\n            \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error analizando chunk: {str(e)}\")\n            return None\n    \n    def extract_features(self, audio, sr):\n        \"\"\"Extraer caracter√≠sticas de audio para todos los modelos\"\"\"\n        \n        features = {\n            'technical': None,\n            'musical': None,\n            'transition': None,\n            'crowd': None\n        }\n        \n        try:\n            # Caracter√≠sticas t√©cnicas (mel spectrogram)\n            mel_spec = librosa.feature.melspectrogram(\n                y=audio, sr=sr, n_mels=128, fmax=8000\n            )\n            mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n            mel_db = (mel_db - mel_db.mean()) / mel_db.std()\n            \n            # Redimensionar a tama√±o fijo\n            target_frames = 130\n            if mel_db.shape[1] < target_frames:\n                pad_width = target_frames - mel_db.shape[1]\n                mel_db = np.pad(mel_db, ((0, 0), (0, pad_width)), mode='constant')\n            else:\n                mel_db = mel_db[:, :target_frames]\n            \n            features['technical'] = mel_db.reshape(128, 130, 1)\n            \n            # Caracter√≠sticas musicales\n            chroma = librosa.feature.chroma_stft(y=audio, sr=sr)\n            chroma_mean = np.mean(chroma, axis=1)\n            \n            tonnetz = librosa.feature.tonnetz(y=audio, sr=sr)\n            tonnetz_mean = np.mean(tonnetz, axis=1)\n            \n            tempo, beats = librosa.beat.beat_track(y=audio, sr=sr)\n            tempo_features = [\n                tempo,\n                len(beats) / (len(audio) / sr),\n                np.std(np.diff(beats)) if len(beats) > 1 else 0,\n            ]\n            \n            spectral_centroids = librosa.feature.spectral_centroid(y=audio, sr=sr)\n            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n            zcr = librosa.feature.zero_crossing_rate(audio)\n            \n            rhythm_features = tempo_features + [\n                np.mean(spectral_centroids),\n                np.std(spectral_centroids),\n                np.mean(spectral_rolloff),\n                np.std(spectral_rolloff),\n                np.mean(zcr)\n            ]\n            \n            features['musical'] = [chroma_mean, tonnetz_mean, rhythm_features]\n            \n            # Caracter√≠sticas de transici√≥n (simplificado para tiempo real)\n            mid_point = len(audio) // 2\n            segment_length = sr * 7  # 7 segundos por segmento\n            \n            if len(audio) >= segment_length * 2:\n                segment1 = audio[mid_point - segment_length:mid_point]\n                segment2 = audio[mid_point:mid_point + segment_length]\n                \n                mel1 = librosa.feature.melspectrogram(y=segment1, sr=sr, n_mels=128)\n                mel2 = librosa.feature.melspectrogram(y=segment2, sr=sr, n_mels=128)\n                \n                mel1_db = librosa.power_to_db(mel1, ref=np.max)\n                mel2_db = librosa.power_to_db(mel2, ref=np.max)\n                \n                # Redimensionar\n                target_frames = 65\n                for mel_segment in [mel1_db, mel2_db]:\n                    if mel_segment.shape[1] < target_frames:\n                        pad_width = target_frames - mel_segment.shape[1]\n                        mel_segment = np.pad(mel_segment, ((0, 0), (0, pad_width)), mode='constant')\n                    else:\n                        mel_segment = mel_segment[:, :target_frames]\n                \n                features['transition'] = [\n                    np.expand_dims(mel1_db.reshape(128, 65, 1), axis=0),\n                    np.expand_dims(mel2_db.reshape(128, 65, 1), axis=0)\n                ]\n            \n            # Caracter√≠sticas de respuesta de multitud\n            rms = librosa.feature.rms(y=audio)\n            energy_features = [np.mean(rms), np.std(rms), np.max(rms)]\n            \n            spectral_features = [\n                np.mean(spectral_centroids), np.std(spectral_centroids),\n                np.mean(spectral_rolloff), np.std(spectral_rolloff)\n            ]\n            \n            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n            mfcc_means = np.mean(mfccs, axis=1)\n            \n            contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)\n            contrast_mean = np.mean(contrast, axis=1)\n            \n            crowd_features = np.concatenate([\n                energy_features,\n                spectral_features,\n                [tempo],\n                mfcc_means,\n                contrast_mean\n            ])\n            \n            features['crowd'] = crowd_features\n            \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error extrayendo caracter√≠sticas: {str(e)}\")\n        \n        return features\n    \n    def prepare_ensemble_input(self, results):\n        \"\"\"Preparar entrada para el modelo ensemble\"\"\"\n        \n        technical_features = np.array(list(results['technical'].values()))\n        musical_features = np.array(list(results['musical'].values()))\n        transition_features = np.array([results['transition']['quality']])\n        crowd_features = np.array([results['crowd']['energy_level']])\n        \n        return [\n            np.expand_dims(technical_features, axis=0),\n            np.expand_dims(musical_features, axis=0),\n            np.expand_dims(transition_features, axis=0),\n            np.expand_dims(crowd_features, axis=0)\n        ]\n    \n    def send_real_time_results(self, results):\n        \"\"\"Enviar resultados en tiempo real al servidor\"\"\"\n        \n        if self.ws:\n            message = {\n                'type': 'ai_analysis_results',\n                'battle_id': getattr(self, 'current_battle_id', None),\n                'results': results,\n                'timestamp': datetime.now().isoformat()\n            }\n            \n            try:\n                self.ws.send(json.dumps(message))\n            except Exception as e:\n                self.logger.error(f\"‚ùå Error enviando resultados: {str(e)}\")\n    \n    def end_battle_analysis(self, battle_id):\n        \"\"\"Finalizar an√°lisis de batalla y generar reporte final\"\"\"\n        \n        self.logger.info(f\"üèÅ Finalizando an√°lisis para batalla: {battle_id}\")\n        \n        self.is_running = False\n        \n        # Generar reporte final\n        final_report = self.generate_final_report()\n        \n        # Enviar reporte al servidor\n        if self.ws:\n            message = {\n                'type': 'ai_final_report',\n                'battle_id': battle_id,\n                'report': final_report,\n                'timestamp': datetime.now().isoformat()\n            }\n            self.ws.send(json.dumps(message))\n        \n        # Limpiar datos\n        self.audio_buffer = np.array([])\n        self.analysis_results = []\n    \n    def generate_final_report(self):\n        \"\"\"Generar reporte final de la batalla\"\"\"\n        \n        if not self.analysis_results:\n            return {'error': 'No hay datos de an√°lisis disponibles'}\n        \n        # Agregar resultados por categor√≠a\n        technical_scores = []\n        musical_scores = []\n        transition_scores = []\n        crowd_scores = []\n        final_scores = []\n        \n        for result in self.analysis_results:\n            if result.get('technical'):\n                technical_scores.append(list(result['technical'].values()))\n            if result.get('musical'):\n                musical_scores.append(list(result['musical'].values()))\n            if result.get('transition'):\n                transition_scores.append(result['transition']['quality'])\n            if result.get('crowd'):\n                crowd_scores.append(result['crowd']['energy_level'])\n            if result.get('final_score'):\n                final_scores.append(result['final_score'])\n        \n        # Calcular estad√≠sticas\n        report = {\n            'summary': {\n                'total_analyses': len(self.analysis_results),\n                'average_final_score': float(np.mean(final_scores)) if final_scores else 0.0,\n                'score_std': float(np.std(final_scores)) if final_scores else 0.0,\n                'max_score': float(np.max(final_scores)) if final_scores else 0.0,\n                'min_score': float(np.min(final_scores)) if final_scores else 0.0\n            },\n            'technical_analysis': {\n                'average_scores': np.mean(technical_scores, axis=0).tolist() if technical_scores else [],\n                'score_evolution': [np.mean(score) for score in technical_scores] if technical_scores else []\n            },\n            'musical_analysis': {\n                'average_scores': np.mean(musical_scores, axis=0).tolist() if musical_scores else [],\n                'score_evolution': [np.mean(score) for score in musical_scores] if musical_scores else []\n            },\n            'transition_analysis': {\n                'average_quality': float(np.mean(transition_scores)) if transition_scores else 0.0,\n                'quality_evolution': transition_scores\n            },\n            'crowd_analysis': {\n                'average_energy': float(np.mean(crowd_scores)) if crowd_scores else 0.0,\n                'energy_evolution': crowd_scores\n            },\n            'recommendations': self.generate_recommendations()\n        }\n        \n        return report\n    \n    def generate_recommendations(self):\n        \"\"\"Generar recomendaciones basadas en el an√°lisis\"\"\"\n        \n        recommendations = []\n        \n        if not self.analysis_results:\n            return recommendations\n        \n        # Analizar patrones y tendencias\n        recent_results = self.analysis_results[-10:] if len(self.analysis_results) > 10 else self.analysis_results\n        \n        # Recomendaciones t√©cnicas\n        technical_scores = [r.get('technical', {}) for r in recent_results]\n        if technical_scores:\n            avg_bpm_accuracy = np.mean([t.get('bpm_accuracy', 0) for t in technical_scores])\n            if avg_bpm_accuracy < 0.7:\n                recommendations.append(\"Mejorar precisi√≥n de BPM y sincronizaci√≥n\")\n            \n            avg_transition = np.mean([t.get('transition_smoothness', 0) for t in technical_scores])\n            if avg_transition < 0.6:\n                recommendations.append(\"Trabajar en transiciones m√°s suaves\")\n        \n        # Recomendaciones musicales\n        musical_scores = [r.get('musical', {}) for r in recent_results]\n        if musical_scores:\n            avg_harmony = np.mean([m.get('harmonic_mixing', 0) for m in musical_scores])\n            if avg_harmony < 0.6:\n                recommendations.append(\"Estudiar teor√≠a musical y mezcla arm√≥nica\")\n        \n        return recommendations\n    \n    def analyze_file(self, audio_file_path):\n        \"\"\"Analizar un archivo de audio completo (no en tiempo real)\"\"\"\n        \n        self.logger.info(f\"üéµ Analizando archivo: {audio_file_path}\")\n        \n        try:\n            # Cargar audio\n            audio, sr = librosa.load(audio_file_path, sr=self.config['sample_rate'])\n            \n            # Dividir en chunks para an√°lisis\n            chunk_size = sr * self.config['chunk_duration']\n            overlap_size = sr * self.config['overlap']\n            \n            results = []\n            \n            for i in range(0, len(audio) - chunk_size, chunk_size - overlap_size):\n                chunk = audio[i:i + chunk_size]\n                \n                chunk_result = self.analyze_audio_chunk(chunk, {})\n                if chunk_result:\n                    chunk_result['start_time'] = i / sr\n                    chunk_result['end_time'] = (i + chunk_size) / sr\n                    results.append(chunk_result)\n            \n            # Generar reporte\n            self.analysis_results = results\n            final_report = self.generate_final_report()\n            \n            return {\n                'file_path': audio_file_path,\n                'chunk_results': results,\n                'final_report': final_report\n            }\n            \n        except Exception as e:\n            self.logger.error(f\"‚ùå Error analizando archivo: {str(e)}\")\n            return None\n    \n    def start_real_time_analysis(self):\n        \"\"\"Iniciar an√°lisis en tiempo real (conectar WebSocket)\"\"\"\n        \n        self.logger.info(\"üî¥ Iniciando an√°lisis en tiempo real...\")\n        self.connect_websocket()\n    \n    def stop_analysis(self):\n        \"\"\"Detener an√°lisis\"\"\"\n        \n        self.is_running = False\n        if self.ws:\n            self.ws.close()\n        \n        self.logger.info(\"‚èπÔ∏è An√°lisis detenido\")\n\nif __name__ == \"__main__\":\n    # Ejemplo de uso\n    judge = DJBattleAIJudge()\n    \n    # Para an√°lisis en tiempo real\n    judge.start_real_time_analysis()\n    \n    # Para an√°lisis de archivo\n    # result = judge.analyze_file('./test_audio.wav')\n    # print(json.dumps(result, indent=2))\n    \n    print(\"üéØ AI Judge listo para evaluar batallas\")"