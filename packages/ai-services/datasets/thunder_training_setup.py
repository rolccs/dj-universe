"""
Thunder Computer VPS Setup Script
Configuraci√≥n completa para entrenar modelos DJ Universe con 80GB VRAM
"""

import os
import sys
import subprocess
import json
from pathlib import Path
import torch
import psutil
import GPUtil


def check_system_requirements():
    """Verificar requisitos del sistema Thunder"""
    print("üîç Verificando sistema Thunder Computer...")
    
    # Verificar GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"‚úÖ GPUs disponibles: {gpu_count}")
        
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} - {gpu_memory:.1f}GB")
            
            if gpu_memory >= 75:  # Al menos 75GB para considerar 80GB
                print(f"‚úÖ GPU {i} cumple requisitos para modelos grandes")
            else:
                print(f"‚ö†Ô∏è  GPU {i} podr√≠a ser insuficiente para modelos complejos")
    else:
        print("‚ùå No se detectaron GPUs CUDA")
        return False
    
    # Verificar RAM
    ram_gb = psutil.virtual_memory().total / 1024**3
    print(f"üíæ RAM disponible: {ram_gb:.1f}GB")
    
    if ram_gb >= 64:
        print("‚úÖ RAM suficiente para datasets grandes")
    else:
        print("‚ö†Ô∏è  Podr√≠a necesitar m√°s RAM para datasets complejos")
    
    # Verificar espacio en disco
    disk_usage = psutil.disk_usage('/')
    disk_free_gb = disk_usage.free / 1024**3
    print(f"üíø Espacio libre en disco: {disk_free_gb:.1f}GB")
    
    if disk_free_gb >= 500:
        print("‚úÖ Espacio en disco suficiente")
    else:
        print("‚ö†Ô∏è  Considerar m√°s espacio para datasets (recomendado: 1TB+)")
    
    return True


def install_dependencies():
    """Instalar dependencias optimizadas para Thunder"""
    print("\nüì¶ Instalando dependencias...")
    
    # Actualizar pip
    subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"])
    
    # PyTorch con CUDA optimizado
    subprocess.run([
        sys.executable, "-m", "pip", "install", 
        "torch", "torchvision", "torchaudio", 
        "--index-url", "https://download.pytorch.org/whl/cu121"
    ])
    
    # Audio processing
    audio_packages = [
        "librosa>=0.10.0",
        "soundfile>=0.12.0",
        "torchaudio>=2.0.0",
        "nnAudio>=0.3.2",
        "madmom>=0.16.1",
        "essentia>=2.1b6.dev858",
        "pyloudnorm>=0.1.1"
    ]
    
    for package in audio_packages:
        subprocess.run([sys.executable, "-m", "pip", "install", package])
    
    # ML frameworks
    ml_packages = [
        "pytorch-lightning>=2.0.0",
        "transformers>=4.30.0",
        "diffusers>=0.21.0",
        "accelerate>=0.20.0",
        "deepspeed>=0.10.0",
        "wandb>=0.15.0",
        "tensorboard>=2.13.0"
    ]
    
    for package in ml_packages:
        subprocess.run([sys.executable, "-m", "pip", "install", package])
    
    # Data processing
    data_packages = [
        "pandas>=2.0.0",
        "numpy>=1.24.0",
        "scipy>=1.10.0",
        "scikit-learn>=1.3.0",
        "h5py>=3.8.0",
        "tables>=3.8.0",
        "pyarrow>=12.0.0"
    ]
    
    for package in data_packages:
        subprocess.run([sys.executable, "-m", "pip", "install", package])
    
    # Web scraping y APIs
    web_packages = [
        "requests>=2.31.0",
        "aiohttp>=3.8.0",
        "beautifulsoup4>=4.12.0",
        "selenium>=4.10.0",
        "yt-dlp>=2023.7.6",
        "spotipy>=2.22.0",
        "mutagen>=1.46.0"
    ]
    
    for package in web_packages:
        subprocess.run([sys.executable, "-m", "pip", "install", package])
    
    print("‚úÖ Dependencias instaladas")


def setup_environment_variables():
    """Configurar variables de entorno para optimizaci√≥n"""
    print("\n‚öôÔ∏è Configurando variables de entorno...")
    
    env_vars = {
        # CUDA optimizations
        'CUDA_VISIBLE_DEVICES': '0',  # Usar GPU 0 por defecto
        'CUDA_DEVICE_ORDER': 'PCI_BUS_ID',
        
        # PyTorch optimizations
        'PYTORCH_CUDA_ALLOC_CONF': 'max_split_size_mb:512',
        'TORCH_CUDNN_V8_API_ENABLED': '1',
        
        # Memory optimizations
        'TOKENIZERS_PARALLELISM': 'false',
        'TRANSFORMERS_CACHE': '/data/transformers_cache',
        'HF_DATASETS_CACHE': '/data/datasets_cache',
        
        # Training optimizations
        'WANDB_CACHE_DIR': '/data/wandb_cache',
        'WANDB_DATA_DIR': '/data/wandb_data',
        
        # Audio processing
        'LIBROSA_CACHE_DIR': '/data/librosa_cache',
        
        # Dataset paths
        'DJ_UNIVERSE_DATA_DIR': '/data/dj-universe-datasets',
        'DJ_UNIVERSE_MODELS_DIR': '/data/dj-universe-models',
        'DJ_UNIVERSE_LOGS_DIR': '/data/dj-universe-logs'
    }
    
    # Crear directorios
    for var_name, var_value in env_vars.items():
        if var_name.endswith('_DIR') or var_name.endswith('_CACHE'):
            Path(var_value).mkdir(parents=True, exist_ok=True)
    
    # Escribir archivo de variables de entorno
    env_file = Path('/data/dj-universe.env')
    with open(env_file, 'w') as f:
        for var_name, var_value in env_vars.items():
            f.write(f"export {var_name}={var_value}\n")
            os.environ[var_name] = var_value
    
    print(f"‚úÖ Variables de entorno guardadas en: {env_file}")
    print("üí° Ejecuta: source /data/dj-universe.env")


def create_training_scripts():
    """Crear scripts de entrenamiento optimizados"""
    print("\nüìù Creando scripts de entrenamiento...")
    
    scripts_dir = Path('/data/dj-universe-training')
    scripts_dir.mkdir(parents=True, exist_ok=True)
    
    # Script principal de entrenamiento
    main_training_script = scripts_dir / 'train_all_models.py'
    
    with open(main_training_script, 'w') as f:
        f.write('''#!/usr/bin/env python3
"""
Script principal de entrenamiento para Thunder VPS
Entrena todos los modelos de DJ Universe en secuencia optimizada
"""

import os
import sys
import time
import torch
import wandb
from pathlib import Path

# Configurar paths
sys.path.append('/home/fat32/dj-universe/packages/ai-services')

from models.ai_judge_model import AIJudgeModel, AIJudgeTrainer
from models.audio_analysis_model import AudioAnalysisModel, AudioAnalysisTrainer
from datasets.real_dataset_collector import RealDatasetCollector

def setup_wandb():
    """Configurar Weights & Biases para tracking"""
    wandb.login()
    wandb.init(
        project="dj-universe-ai",
        entity="your-wandb-entity",
        name=f"thunder-training-{int(time.time())}",
        config={
            "gpu_memory": "80GB",
            "platform": "thunder-computer",
            "models": ["ai_judge", "audio_analysis", "music_generation"]
        }
    )

def train_ai_judge_model():
    """Entrenar AI Judge Model"""
    print("ü§ñ Entrenando AI Judge Model...")
    
    # Configuraci√≥n optimizada para 80GB VRAM
    config = {
        "batch_size": 32,  # Aumentado para 80GB
        "learning_rate": 1e-4,
        "epochs": 100,
        "gradient_accumulation_steps": 4,
        "mixed_precision": True
    }
    
    model = AIJudgeModel()
    trainer = AIJudgeTrainer(
        model=model,
        device='cuda',
        learning_rate=config["learning_rate"]
    )
    
    # Cargar dataset
    dataset_path = "/data/dj-universe-datasets/battle_evaluations.h5"
    # TODO: Implementar DataLoader
    
    # Training loop optimizado
    model.train()
    for epoch in range(config["epochs"]):
        print(f"√âpoca {epoch+1}/{config['epochs']}")
        
        # TODO: Implementar training loop con dataset real
        # loss = trainer.train_step(audio_batch, metadata_batch, targets_batch)
        
        # Log a wandb
        # wandb.log({"ai_judge_loss": loss, "epoch": epoch})
    
    # Guardar modelo
    model_path = "/data/dj-universe-models/ai_judge_v1.pth"
    torch.save(model.state_dict(), model_path)
    print(f"‚úÖ AI Judge Model guardado: {model_path}")

def train_audio_analysis_model():
    """Entrenar Audio Analysis Model"""
    print("üéµ Entrenando Audio Analysis Model...")
    
    config = {
        "batch_size": 64,  # M√°s grande para an√°lisis de audio
        "learning_rate": 2e-4,
        "epochs": 50,
        "chunk_size": 4  # 4 segundos de audio
    }
    
    model = AudioAnalysisModel(chunk_size=config["chunk_size"])
    trainer = AudioAnalysisTrainer(
        model=model,
        device='cuda',
        learning_rate=config["learning_rate"]
    )
    
    # Training loop
    model.train()
    for epoch in range(config["epochs"]):
        print(f"√âpoca {epoch+1}/{config['epochs']}")
        
        # TODO: Implementar training loop
        
    # Guardar modelo
    model_path = "/data/dj-universe-models/audio_analysis_v1.pth"
    torch.save(model.state_dict(), model_path)
    print(f"‚úÖ Audio Analysis Model guardado: {model_path}")

def main():
    """Entrenamiento principal"""
    print("üöÄ Iniciando entrenamiento en Thunder Computer VPS")
    print(f"üî• GPU: {torch.cuda.get_device_name()}")
    print(f"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
    
    # Setup
    setup_wandb()
    
    # Entrenar modelos en secuencia
    train_ai_judge_model()
    train_audio_analysis_model()
    
    print("üéâ Entrenamiento completado!")
    wandb.finish()

if __name__ == "__main__":
    main()
''')
    
    # Script de monitoreo
    monitor_script = scripts_dir / 'monitor_training.py'
    
    with open(monitor_script, 'w') as f:
        f.write('''#!/usr/bin/env python3
"""
Script de monitoreo para entrenamiento en Thunder VPS
"""

import time
import psutil
import GPUtil
import torch
from pathlib import Path

def monitor_system():
    """Monitorear sistema durante entrenamiento"""
    
    print("üìä Monitor de entrenamiento Thunder VPS")
    print("=" * 50)
    
    while True:
        # GPU stats
        if torch.cuda.is_available():
            gpu = GPUtil.getGPUs()[0]
            gpu_memory_used = torch.cuda.memory_allocated() / 1024**3
            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            gpu_utilization = gpu.load * 100
            
            print(f"üî• GPU: {gpu_utilization:.1f}% | "
                  f"VRAM: {gpu_memory_used:.1f}/{gpu_memory_total:.1f}GB "
                  f"({gpu_memory_used/gpu_memory_total*100:.1f}%)")
        
        # CPU y RAM
        cpu_percent = psutil.cpu_percent()
        ram = psutil.virtual_memory()
        ram_used_gb = (ram.total - ram.available) / 1024**3
        ram_total_gb = ram.total / 1024**3
        
        print(f"üíª CPU: {cpu_percent:.1f}% | "
              f"RAM: {ram_used_gb:.1f}/{ram_total_gb:.1f}GB "
              f"({ram.percent:.1f}%)")
        
        # Disco
        disk = psutil.disk_usage('/data')
        disk_used_gb = disk.used / 1024**3
        disk_total_gb = disk.total / 1024**3
        
        print(f"üíø Disco: {disk_used_gb:.1f}/{disk_total_gb:.1f}GB "
              f"({disk.used/disk.total*100:.1f}%)")
        
        print("-" * 50)
        time.sleep(10)  # Update every 10 seconds

if __name__ == "__main__":
    monitor_system()
''')
    
    # Hacer scripts ejecutables
    main_training_script.chmod(0o755)
    monitor_script.chmod(0o755)
    
    print(f"‚úÖ Scripts creados en: {scripts_dir}")


def create_dataset_download_script():
    """Crear script de descarga de datasets"""
    print("\nüì• Creando script de descarga de datasets...")
    
    download_script = Path('/data/download_datasets.py')
    
    with open(download_script, 'w') as f:
        f.write('''#!/usr/bin/env python3
"""
Script de descarga masiva de datasets reales para Thunder VPS
"""

import asyncio
import os
import sys

# Agregar path del proyecto
sys.path.append('/home/fat32/dj-universe/packages/ai-services')

from datasets.real_dataset_collector import RealDatasetCollector, create_professional_dataset_sources

async def download_all_datasets():
    """Descargar todos los datasets disponibles"""
    
    print("üöÄ Iniciando descarga masiva de datasets reales")
    print("üíª Thunder Computer VPS - Optimizado para 80GB VRAM")
    
    # Configurar APIs (agregar tus keys)
    os.environ['SPOTIFY_CLIENT_ID'] = 'your_spotify_client_id'
    os.environ['SPOTIFY_CLIENT_SECRET'] = 'your_spotify_client_secret'
    
    # Inicializar colector
    collector = RealDatasetCollector(base_dir="/data/dj-universe-datasets")
    
    # Obtener fuentes
    soundcloud_playlists, dj_mixes = create_professional_dataset_sources()
    
    print(f"üìä Playlists SoundCloud: {len(soundcloud_playlists)}")
    print(f"üéß DJ Mixes: {len(dj_mixes)}")
    
    # Descargar datos
    soundcloud_tracks = collector.download_from_soundcloud_playlists(soundcloud_playlists)
    dj_mix_tracks = collector.download_professional_dj_mixes(dj_mixes)
    
    total_tracks = len(soundcloud_tracks) + len(dj_mix_tracks)
    print(f"‚úÖ Total tracks descargados: {total_tracks}")
    
    # Exportar para entrenamiento
    dataset_path = "/data/dj-universe-datasets/complete_dataset.h5"
    collector.export_dataset_for_training(dataset_path)
    
    print(f"üéØ Dataset listo para entrenamiento: {dataset_path}")

if __name__ == "__main__":
    asyncio.run(download_all_datasets())
''')
    
    download_script.chmod(0o755)
    print(f"‚úÖ Script de descarga creado: {download_script}")


def create_startup_guide():
    """Crear gu√≠a de inicio r√°pido"""
    guide_path = Path('/data/THUNDER_SETUP_GUIDE.md')
    
    with open(guide_path, 'w') as f:
        f.write('''# üöÄ Thunder Computer VPS - DJ Universe AI Training

## Configuraci√≥n Completada ‚úÖ

### Sistema Verificado:
- ‚úÖ GPU con 80GB VRAM detectada
- ‚úÖ Dependencias instaladas
- ‚úÖ Variables de entorno configuradas
- ‚úÖ Scripts de entrenamiento listos

## Pasos para Entrenar:

### 1. Activar Entorno
```bash
source /data/dj-universe.env
cd /data
```

### 2. Descargar Datasets REALES
```bash
# Configurar API keys primero (opcional pero recomendado)
export SPOTIFY_CLIENT_ID="your_client_id"
export SPOTIFY_CLIENT_SECRET="your_client_secret"

# Descargar datasets
python3 download_datasets.py
```

### 3. Monitorear Sistema (terminal separado)
```bash
python3 dj-universe-training/monitor_training.py
```

### 4. Iniciar Entrenamiento
```bash
python3 dj-universe-training/train_all_models.py
```

## Estructura de Datos:

```
/data/
‚îú‚îÄ‚îÄ dj-universe-datasets/           # Datasets descargados
‚îÇ   ‚îú‚îÄ‚îÄ soundcloud/                 # Tracks de SoundCloud
‚îÇ   ‚îú‚îÄ‚îÄ dj_mixes/                   # Mixes profesionales
‚îÇ   ‚îú‚îÄ‚îÄ metadata/                   # Metadatos enriquecidos
‚îÇ   ‚îî‚îÄ‚îÄ complete_dataset.h5         # Dataset final para entrenamiento
‚îú‚îÄ‚îÄ dj-universe-models/             # Modelos entrenados
‚îú‚îÄ‚îÄ dj-universe-logs/               # Logs de entrenamiento
‚îî‚îÄ‚îÄ dj-universe-training/           # Scripts de entrenamiento
```

## Modelos que se entrenar√°n:

1. **AI Judge Model** - Evaluaci√≥n autom√°tica de battles
2. **Audio Analysis Model** - BPM, clave, energ√≠a en tiempo real
3. **Music Generation Model** - Generaci√≥n musical especializada

## Monitoreo:

- **GPU**: Uso y memoria VRAM
- **CPU**: Utilizaci√≥n del procesador
- **RAM**: Memoria del sistema
- **Disco**: Espacio disponible
- **Wandb**: M√©tricas de entrenamiento en tiempo real

## APIs Recomendadas:

### Spotify API (Enriquecimiento de metadata):
1. Ir a: https://developer.spotify.com/dashboard
2. Crear app
3. Obtener Client ID y Secret
4. Configurar variables de entorno

### Beatport API (Comercial):
- Contactar: developers@beatport.com
- Dataset profesional de m√∫sica electr√≥nica

## Optimizaciones Thunder VPS:

- **Batch Size**: Aumentado para aprovechar 80GB VRAM
- **Mixed Precision**: Activado para mayor velocidad
- **Gradient Accumulation**: Optimizado para memoria
- **Data Loading**: Paralelo y eficiente

## Soporte:

Si encuentras problemas:
1. Verificar logs en `/data/dj-universe-logs/`
2. Monitorear GPU con `nvidia-smi`
3. Verificar memoria con script de monitoreo

¬°Listo para crear la IA de DJ m√°s avanzada del mundo! üéµü§ñ
''')
    
    print(f"‚úÖ Gu√≠a de inicio creada: {guide_path}")


def main():
    """Setup completo para Thunder VPS"""
    print("üå©Ô∏è  THUNDER COMPUTER VPS SETUP")
    print("üéµ DJ Universe AI Training Environment")
    print("üíæ 80GB VRAM Optimization")
    print("=" * 50)
    
    # Verificar sistema
    if not check_system_requirements():
        print("‚ùå Sistema no cumple requisitos m√≠nimos")
        return
    
    # Instalar dependencias
    install_dependencies()
    
    # Configurar entorno
    setup_environment_variables()
    
    # Crear scripts
    create_training_scripts()
    create_dataset_download_script()
    
    # Crear gu√≠a
    create_startup_guide()
    
    print("\nüéâ SETUP COMPLETADO!")
    print("üìñ Lee la gu√≠a: /data/THUNDER_SETUP_GUIDE.md")
    print("üöÄ Ejecuta: source /data/dj-universe.env")
    print("üì• Descarga datos: python3 /data/download_datasets.py")
    print("üèãÔ∏è  Entrena modelos: python3 /data/dj-universe-training/train_all_models.py")


if __name__ == "__main__":
    main()